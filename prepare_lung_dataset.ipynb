{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xml.dom.minidom\n",
    "import os\n",
    "from shutil import copy2\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# INITIALIZE DATASET PATTERNe\n",
    "dataset = 'attgan'\n",
    "\n",
    "# with open('captions_train2014.json', 'wb') as train_captions, \\\n",
    "#     open('captions_val2014.json', 'wb') as val_captions, \\\n",
    "#     open('imgs_train_path.txt', 'wb') as train_path, \\\n",
    "#     open('imgs_val_path.txt', 'wb') as val_path:   \n",
    "with open(os.path.join('/media/hd1/home/wangwei/attn-gan/data/lung/train', \\\n",
    "                       'filenames.pickle'), 'wb') as train_names, \\\n",
    "     open(os.path.join('/media/hd1/home/wangwei/attn-gan/data/lung/test', \\\n",
    "                       'filenames.pickle'), 'wb') as test_names:\n",
    "        \n",
    "    if dataset in ('coco', 'genome'):\n",
    "        train_json_data = {}\n",
    "        train_json_data['images'] = []\n",
    "        train_json_data['annotations'] = []        \n",
    "        val_json_data = {}\n",
    "        val_json_data['images'] = []\n",
    "        val_json_data['annotations'] = []\n",
    "        \n",
    "        # we also need the following\n",
    "        #res.dataset['info']\n",
    "        #res.dataset['type']\n",
    "        #res.dataset['licenses']\n",
    "    elif dataset == 'karp':\n",
    "        # init dict data\n",
    "        json_data = {}\n",
    "        json_data['images'] = []\n",
    "        json_data['dataset'] = 'coco'\n",
    "        \n",
    "    elif dataset == 'attgan':\n",
    "        train_name_list = []\n",
    "        test_name_list = []\n",
    "    \n",
    "    else:\n",
    "        print 'not implemented yet'\n",
    "        \n",
    "    \n",
    "    i, j = 0, 0\n",
    "    \n",
    "    for xmlfile in os.listdir('../lung-report/ecgen-radiology/'): \n",
    "        print xmlfile\n",
    "\n",
    "        DomTree = xml.dom.minidom.parse('../lung-report/ecgen-radiology/'+xmlfile)\n",
    "        eCitation = DomTree.childNodes[0]\n",
    "        parentImages = eCitation.getElementsByTagName('parentImage')\n",
    "\n",
    "        MedlineCitation = eCitation.getElementsByTagName('MedlineCitation')[0]\n",
    "        Abstract = MedlineCitation.getElementsByTagName('Abstract')[0]\n",
    "\n",
    "        \n",
    "        try:\n",
    "            # COMPARISON = Abstract.getElementsByTagName('AbstractText')[0].firstChild.data\n",
    "            # INDICATION = Abstract.getElementsByTagName('AbstractText')[1].firstChild.data\n",
    "            FINDINGS = Abstract.getElementsByTagName('AbstractText')[2].firstChild.data\n",
    "            # IMPRESSION = Abstract.getElementsByTagName('AbstractText')[3].firstChild.data\n",
    "            \n",
    "            # TRUNCATE LONG DESCRIPTION\n",
    "            if len(FINDINGS.split(' ')) > 50:\n",
    "                FINDINGS = ' '.join(FINDINGS.split(' ')[:50])\n",
    "            \n",
    "            j += 1 # report id\n",
    "\n",
    "            for parentImage in parentImages:\n",
    "                \n",
    "                i += 1 # image id\n",
    "                \n",
    "                if dataset == 'coco':\n",
    "                    anno = {}\n",
    "                    anno['image_id'] = i\n",
    "                    anno['id'] = j\n",
    "                    anno['caption'] = FINDINGS\n",
    "                    \n",
    "                    img = {}\n",
    "                    img['file_name'] = parentImage.attributes.items()[0][1] + '.png'\n",
    "                    img['id'] = i\n",
    "                    \n",
    "                elif dataset == 'karp':\n",
    "                    sent = {}\n",
    "                    sent['imgid'], sent['sentids'] = i, i\n",
    "                    sent['raw'] = FINDINGS\n",
    "                    for char in  ['!', '?', '\\'', ',', ';', '.', ':']:\n",
    "                        FINDINGS = FINDINGS.replace(char, '')\n",
    "                    sent['tokens'] = [x.lower() for x in FINDINGS.split(' ')]\n",
    "                    \n",
    "                    img = {}\n",
    "                    img['filename'] = parentImage.attributes.items()[0][1] + '.png'\n",
    "                    img['imgid'], img['sentids'], img['cocoid'] = i, [i], i\n",
    "                    img['sentences'] = [sent]                    \n",
    "                    \n",
    "                elif dataset == 'attgan':\n",
    "                    # one txt file for one caption\n",
    "                    for char in  ['!', '?', '\\'', ',', ';', '.', ':']:\n",
    "                        FINDINGS = FINDINGS.replace(char, '')\n",
    "                    with open(os.path.join('/media/hd1/home/wangwei/attn-gan/data/lung/text', \\\n",
    "                            (parentImage.attributes.items()[0][1] + '.txt')), 'wb') as txt_file:\n",
    "                        txt_file.write(FINDINGS)\n",
    "                \n",
    "                # 70% 4532, 80% 5178, 90% 5825\n",
    "                if i < 5825:  \n",
    "                    if dataset == 'coco':\n",
    "                        train_json_data['images'].append(img)\n",
    "                        train_json_data['annotations'].append(anno)\n",
    "                        \n",
    "                    elif dataset == 'genome':\n",
    "                        train_path.write('../lung-report/image/' + \\\n",
    "                                         parentImage.attributes.items()[0][1] + '.png' + '\\n')                        \n",
    "                        train_captions.write('{' + '\\\"image_id\\\": ' + \\\n",
    "                                             parentImage.attributes.items()[0][1] + ',' + \\\n",
    "                                             '\\\"id\\\": ' + str(j) + ',' + '\\\"paragraph\\\": ' + '\\\"' + \\\n",
    "                                             FINDINGS + '\\\"' + '},')\n",
    "                        \n",
    "                    elif dataset == 'karp': \n",
    "                        # sentence level, bottom up filling\n",
    "                        img['split'] = 'train'\n",
    "                        img['filepath'] = \"train2014\"\n",
    "                        json_data['images'].append(img)\n",
    "                        \n",
    "                        copy2('../lung-report/image/'+ parentImage.attributes.items()[0][1] + '.png', \\\n",
    "                              './image/train2014/')\n",
    "                              \n",
    "                    elif dataset == 'attgan':\n",
    "                        train_name_list.append(parentImage.attributes.items()[0][1])\n",
    "                    \n",
    "                else:                    \n",
    "                    if dataset == 'coco':\n",
    "                        val_json_data['images'].append(img)\n",
    "                        val_json_data['annotations'].append(anno)\n",
    "                                                \n",
    "                    elif dataset == 'genome':\n",
    "                        val_path.write('../lung-report/image/' + \\\n",
    "                                       parentImage.attributes.items()[0][1] + '.png' + '\\n')\n",
    "                        val_captions.write('{' + '\\\"image_id\\\": ' + \\\n",
    "                                           parentImage.attributes.items()[0][1] + ',' + \\\n",
    "                                           '\\\"id\\\": ' + str(j) + ',' + '\\\"paragraph\\\": ' + '\\\"' + \\\n",
    "                                           FINDINGS + '\\\"' + '},')\n",
    "\n",
    "                    elif dataset == 'karp':                        \n",
    "                        img['split'] = 'test' # also use for val\n",
    "                        img['filepath'] = \"test2014\"\n",
    "                        json_data['images'].append(img)\n",
    "                        \n",
    "                        # duplicate for val\n",
    "                        img['split'] = 'val'\n",
    "                        img['filepath'] = \"val2014\"\n",
    "                        json_data['images'].append(img)\n",
    "                        \n",
    "                        copy2('../lung-report/image/'+ parentImage.attributes.items()[0][1] + '.png', \\\n",
    "                              './image/val2014/')\n",
    "                              \n",
    "                    elif dataset == 'attgan':\n",
    "                        test_name_list.append(parentImage.attributes.items()[0][1])\n",
    "                    \n",
    "                print parentImage.attributes.items()[0][1] + '.png'\n",
    "        \n",
    "        except AttributeError:\n",
    "            print 'This xml has no findings'\n",
    "            pass\n",
    "\n",
    "        \n",
    "    if dataset in ('coco', 'genome'):\n",
    "        json.dump(train_json_data, train_captions)\n",
    "        json.dump(val_json_data, val_captions)\n",
    "                              \n",
    "    elif dataset == 'karp':\n",
    "        json.dump(json_data, train_captions)\n",
    "                              \n",
    "    elif dataset == 'attgan':\n",
    "        pickle.dump(train_name_list, train_names)\n",
    "        pickle.dump(test_name_list, test_names)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat ‘captions_train2014.json’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "%mv captions_train2014.json ./data/dataset_coco.json \n",
    "%rm imgs*.txt\n",
    "%rm imgname*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
